{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from nst_utils import * #nst_utils.py文件中定义了图片预处理、生成白躁图等函数\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline ##使用%matplotlib命令可以将matplotlib的图表直接嵌入到Notebook之中，实验必备\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义代价函数（内容损失+风格损失）\n",
    "\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "- 获得某个 tensor X的维数: `X.get_shape().as_list()`\n",
    "- [tf.transpose用法](https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/transpose) 及 [tf.reshape用法](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/reshape).\n",
    "- [tf.reduce_sum用法](https://www.tensorflow.org/api_docs/python/tf/reduce_sum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算内容损失\n",
    "\n",
    "def compute_content_cost(a_C, a_G):\n",
    "    \"\"\"\n",
    "    Computes the content cost\n",
    "    \n",
    "    Arguments:\n",
    "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_content -- scalar that you compute using equation 1 above.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 获得a_G维数 \n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "#     print(\"m:{0}\".format(m))\n",
    "#     print(\"n_H:{0}\".format(n_H))\n",
    "#     print(\"n_W:{0}\".format(n_W))\n",
    "#     print(\"n_C:{0}\".format(n_C))\n",
    "\n",
    "    # Reshape a_C and a_G \n",
    "    a_C_unrolled = tf.reshape(tf.transpose(a_C, perm=[3, 2, 1, 0]), [n_C, n_H*n_W, -1])\n",
    "    a_G_unrolled = tf.reshape(tf.transpose(a_G, perm=[3, 2, 1, 0]), [n_C, n_H*n_W, -1])\n",
    "    # compute the cost with tensorflow \n",
    "    J_content = tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled))) / (4 * n_H * n_W * n_C)\n",
    "    \n",
    "    return J_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Gram矩阵\n",
    "\n",
    "def gram_matrix(A):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    A -- matrix of shape (n_C, n_H*n_W)\n",
    "    \n",
    "    Returns:\n",
    "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    GA = tf.matmul(A,tf.transpose(A)) #作内积\n",
    "    return GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算一层的风格损失\n",
    "\n",
    "def compute_layer_style_cost(a_S, a_G):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from a_G \n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "\n",
    "    # Reshape the images to have them of shape (n_C, n_H*n_W) \n",
    "    a_S = tf.reshape(tf.transpose(a_S, perm=[3, 1, 2, 0]), [n_C, n_W*n_H])\n",
    "    a_G = tf.reshape(tf.transpose(a_G, perm=[3, 1, 2, 0]), [n_C, n_W*n_H])\n",
    "\n",
    "    # Computing gram_matrices for both images S and G \n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "\n",
    "    # Computing the loss \n",
    "    J_style_layer = tf.reduce_sum(tf.square(tf.subtract(GS, GG))) / (4 * n_C**2 * (n_W * n_H)**2)\n",
    "\n",
    "\n",
    "    \n",
    "    return J_style_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从以下几个层中计算风格损失，数字代表权重\n",
    "\n",
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算多层风格损失\n",
    "\n",
    "def compute_style_cost(model, STYLE_LAYERS):\n",
    "    \"\"\"\n",
    "    Computes the overall style cost from several chosen layers\n",
    "    \n",
    "    Arguments:\n",
    "    model -- our tensorflow model\n",
    "    STYLE_LAYERS -- A python list containing:\n",
    "                        - the names of the layers we would like to extract style from\n",
    "                        - a coefficient for each of them\n",
    "    \n",
    "    Returns: \n",
    "    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the overall style cost\n",
    "    J_style = 0\n",
    "\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "\n",
    "        # Select the output tensor of the currently selected layer\n",
    "        out = model[layer_name]\n",
    "\n",
    "        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out\n",
    "        a_S = sess.run(out)\n",
    "\n",
    "        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] \n",
    "        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
    "        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
    "        a_G = out\n",
    "        \n",
    "        # Compute style_cost for the current layer\n",
    "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
    "\n",
    "        # Add coeff * J_style_layer of this layer to overall style cost\n",
    "        J_style += coeff * J_style_layer\n",
    "\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算总的损失\n",
    "\n",
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "    \"\"\"\n",
    "    Computes the total cost function\n",
    "    \n",
    "    Arguments:\n",
    "    J_content -- content cost coded above\n",
    "    J_style -- style cost coded above\n",
    "    alpha -- hyperparameter weighting the importance of the content cost\n",
    "    beta -- hyperparameter weighting the importance of the style cost\n",
    "    \n",
    "    Returns:\n",
    "    J -- total cost as defined by the formula above.\n",
    "    \"\"\"\n",
    "    \n",
    "    J = alpha*J_content + beta*J_style\n",
    "    \n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成图片\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "- [Interactive Session](https://www.tensorflow.org/api_docs/python/tf/InteractiveSession)是tf的一个类，可以省略掉重复指向对象的过程\n",
    "- 迁移学习，利用预训练好的VGG-19模型进行特征提取\n",
    "- [Adam Optimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)优化生成图片（图像重建）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入内容、风格图片\n",
    "content_image = scipy.misc.imread(\"images/louvre_small.jpg\")\n",
    "content_image = reshape_and_normalize_image(content_image)\n",
    "style_image = scipy.misc.imread(\"images/monet.jpg\")\n",
    "style_image = reshape_and_normalize_image(style_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成白躁图\n",
    "generated_image = generate_noise_image(content_image)\n",
    "imshow(generated_image[0])\n",
    "\n",
    "# 加入预训练好的VGG-19网络\n",
    "model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\n",
    "\n",
    "# 将内容图片作为VGG网络的输入  \n",
    "sess.run(model['input'].assign(content_image))\n",
    "\n",
    "# 选取要提取特征的层conv4_2\n",
    "out = model['conv4_2']\n",
    "a_C = sess.run(out)\n",
    "a_G = out \n",
    "\n",
    "# 计算内容损失\n",
    "J_content = compute_content_cost(a_C, a_G)\n",
    "\n",
    "# 将风格图片作为VGG网络的输入  \n",
    "sess.run(model['input'].assign(style_image))\n",
    "\n",
    "# 计算风格损失\n",
    "J_style = compute_style_cost(model, STYLE_LAYERS)\n",
    "\n",
    "# 计算总的损失\n",
    "J = total_cost(J_content, J_style, alpha = 10, beta = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器AdamOptimizer\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "\n",
    "# 定义训练步长\n",
    "train_step = optimizer.minimize(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义整个神经网络的计算：初始化参数，输入图片，多次迭代优化生成图片\n",
    "def model_nn(sess, input_image, num_iterations = 200):\n",
    "    \n",
    "    # Initialize global variables (you need to run the session on the initializer)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Run the noisy input image (initial generated image) through the model. Use assign().\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    sess.run(model['input'].assign(input_image))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # Run the session on the train_step to minimize the total cost\n",
    "        ### START CODE HERE ### (1 line)\n",
    "        sess.run(train_step)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Compute the generated image by running the session on the current model['input']\n",
    "        ### START CODE HERE ### (1 line)\n",
    "        generated_image = sess.run(model['input'])\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Print every 20 iteration.\n",
    "        if i%20 == 0:\n",
    "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"total cost = \" + str(Jt))\n",
    "            print(\"content cost = \" + str(Jc))\n",
    "            print(\"style cost = \" + str(Js))\n",
    "\n",
    "            # save current generated image in the \"/output\" directory\n",
    "            save_image(\"output/\" + str(i) + \".png\", generated_image)\n",
    "\n",
    "    # save last generated image\n",
    "    save_image('output/generated_image.jpg', generated_image)\n",
    "\n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面这行代码，用CPU要跑3min左右。但在100多次迭代后（每20次迭代后输出一张生成图）基本上就不会有太多变化了。\n",
    "model_nn(sess, generated_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
